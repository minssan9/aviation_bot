# LangChain Chatbot with DocumentDB and Ollama

A production-ready chatbot implementation using LangChain, MongoDB (DocumentDB), and Ollama for local LLM inference.

## ğŸš€ Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository>
   cd langchain-chatbot
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Start services**:
   ```bash
   docker-compose up -d
   ```

3. **Install Ollama and download model**:
   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ollama pull llama3.2:1b
   ```

4. **Ingest sample data**:
   ```bash
   python ingest_data.py
   ```

5. **Run chatbot**:
   ```bash
   # CLI version
   python cli_chat.py
   
   # API version
   python api.py
   ```

## ğŸ“ Project Structure

```
langchain-chatbot/
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ vector_store.py         # MongoDB vector store management
â”œâ”€â”€ chatbot.py             # Core chatbot engine
â”œâ”€â”€ api.py                 # FastAPI REST endpoints
â”œâ”€â”€ cli_chat.py            # Command-line interface
â”œâ”€â”€ ingest_data.py         # Data ingestion script
â”œâ”€â”€ memory.py              # Advanced memory management
â”œâ”€â”€ docker-compose.yml     # Docker services
â”œâ”€â”€ Dockerfile             # Container configuration
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env.example          # Environment variables template
â””â”€â”€ data/                 # Sample documents
    â”œâ”€â”€ python_basics.txt
    â”œâ”€â”€ api_guide.txt
    â””â”€â”€ database_intro.txt
```

## ğŸ”§ Configuration

Copy `.env.example` to `.env` and modify as needed:

```bash
cp .env.example .env
```

## ğŸ³ Docker Usage

Run the complete stack with Docker:

```bash
docker-compose up -d
docker exec -it chatbot_ollama ollama pull llama3.2:1b
```

## ğŸ“š API Documentation

Once the API is running, visit:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### Endpoints

- `POST /chat` - Send a message to the chatbot
- `GET /health` - Health check endpoint

Example request:
```json
{
  "query": "What is Python?"
}
```

## ğŸ§  Features

- **Local LLM**: Uses Ollama for private, offline inference
- **Vector Storage**: MongoDB for efficient document retrieval
- **Memory**: Conversation history management
- **REST API**: FastAPI for web integration
- **CLI Interface**: Direct command-line interaction
- **Docker Support**: Containerized deployment

## ğŸ“– Tutorial

See `chatbot-tutorial.md` for a comprehensive step-by-step guide.

## ğŸ” Troubleshooting

**Common Issues**:

1. **Ollama model not found**:
   ```bash
   ollama pull llama3.2:1b
   ```

2. **MongoDB connection error**:
   ```bash
   docker-compose restart mongodb
   ```

3. **Import errors**:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸš€ Production Deployment

1. **Environment Setup**:
   - Set production MongoDB URI
   - Configure proper authentication
   - Set up SSL/TLS certificates

2. **Scaling**:
   - Use multiple Ollama instances
   - Implement load balancing
   - Set up MongoDB replica sets

3. **Monitoring**:
   - Add logging and metrics
   - Implement health checks
   - Set up alerting

## ğŸ“„ License

MIT License - see LICENSE file for details.